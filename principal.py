import streamlit as st
import pandas as pd
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(
    page_title="An√°lisis Interactivo de √Årboles de Decisi√≥n",
    page_icon="üå≥",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("An√°lisis Interactivo de √Årboles de Decisi√≥n üå≥")
st.markdown("""
Esta aplicaci√≥n te permite generar un conjunto de datos simulado, realizar un an√°lisis exploratorio,
**entrenar un modelo de √Årbol de Decisi√≥n con par√°metros personalizables**, visualizar el √°rbol resultante
y evaluar su desempe√±o en tareas de clasificaci√≥n.
""")

# --- Controles de Generaci√≥n de Datos en el Sidebar ---
st.sidebar.header("Generaci√≥n de Datos Simulados")
n_samples = st.sidebar.slider("N√∫mero de Muestras", min_value=100, max_value=2000, value=300, step=50)
n_features = st.sidebar.slider("N√∫mero de Columnas (Caracter√≠sticas)", min_value=2, max_value=10, value=6, step=1)
n_classes = st.sidebar.slider("N√∫mero de Clases", min_value=2, max_value=5, value=2, step=1)
random_state_data = st.sidebar.number_input("Semilla Aleatoria para Datos", value=42, step=1)

# --- Generaci√≥n del conjunto de datos simulado ---
@st.cache_data
def generate_simulated_data(n_samples, n_features, n_classes, random_state):
    """
    Genera un conjunto de datos simulado para tareas de clasificaci√≥n.
    """
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=min(n_features, n_features - 1),
        n_redundant=max(0, n_features - min(n_features, n_features - 1) - 1),
        n_repeated=0,
        n_classes=n_classes,
        n_clusters_per_class=1,
        class_sep=1.0,
        random_state=random_state,
        flip_y=0.01
    )
    feature_names = [f"Caracter√≠stica_{i+1}" for i in range(X.shape[1])]
    df = pd.DataFrame(X, columns=feature_names)
    df['Clase'] = y
    return df, X, y

# Generar los datos
df, X, y = generate_simulated_data(n_samples, n_features, n_classes, random_state_data)

st.subheader("1. Vista Previa del Conjunto de Datos Simulado")
st.write(f"Conjunto de datos generado con **{df.shape[0]}** muestras y **{df.shape[1]-1}** caracter√≠sticas.")
st.dataframe(df.head()) # Mostrar las primeras filas del DataFrame

# --- Divisi√≥n de los datos en conjuntos de entrenamiento y prueba ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# --- An√°lisis Exploratorio de Datos (EDA) ---
st.markdown("---")
st.subheader("2. An√°lisis Exploratorio de Datos (EDA) üìä")

st.markdown("#### Estad√≠sticas Descriptivas")
st.dataframe(df.describe())

st.markdown("#### Matriz de Correlaci√≥n")
# Excluir la columna 'Clase' para la correlaci√≥n de caracter√≠sticas
fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
sns.heatmap(df.drop('Clase', axis=1).corr(), annot=True, cmap='coolwarm', fmt=".2f", ax=ax_corr)
plt.title("Matriz de Correlaci√≥n entre Caracter√≠sticas")
st.pyplot(fig_corr)

st.markdown("#### Distribuci√≥n de Caracter√≠sticas")
selected_features_for_hist = st.multiselect(
    "Selecciona caracter√≠sticas para ver su distribuci√≥n:",
    options=df.columns[:-1].tolist(),
    default=df.columns[0:min(3, df.shape[1]-1)].tolist()
)
if selected_features_for_hist:
    for feature in selected_features_for_hist:
        fig_hist, ax_hist = plt.subplots(figsize=(8, 5))
        sns.histplot(df[feature], kde=True, ax=ax_hist, color='skyblue')
        plt.title(f"Distribuci√≥n de {feature}")
        plt.xlabel(feature)
        plt.ylabel("Frecuencia")
        st.pyplot(fig_hist)

st.markdown("#### Gr√°fico de Dispersi√≥n Interactivo (Primeras dos caracter√≠sticas)")
st.write("Visualizaci√≥n de las dos primeras caracter√≠sticas principales por clase.")
fig_scatter, ax_scatter = plt.subplots(figsize=(10, 8))
sns.scatterplot(
    x=df.iloc[:, 0], # Primera caracter√≠stica
    y=df.iloc[:, 1], # Segunda caracter√≠stica
    hue=df['Clase'],
    palette='viridis',
    marker='o',
    s=100,
    edgecolor='k',
    ax=ax_scatter
)
plt.title(f"Dispersi√≥n de '{df.columns[0]}' vs '{df.columns[1]}' por Clase")
plt.xlabel(df.columns[0])
plt.ylabel(df.columns[1])
st.pyplot(fig_scatter)

# --- Configuraci√≥n del Modelo de √Årbol de Decisi√≥n ---
st.markdown("---")
st.subheader("3. Configuraci√≥n y Entrenamiento del √Årbol de Decisi√≥n üõ†Ô∏è")

st.sidebar.header("Par√°metros del √Årbol de Decisi√≥n")
# Par√°metros b√°sicos
max_depth = st.sidebar.slider("Profundidad M√°xima (max_depth)", min_value=1, max_value=20, value=7, help="La profundidad m√°xima del √°rbol. Limitar esto previene el sobreajuste.")
min_samples_leaf = st.sidebar.slider("M√≠nimo de Muestras por Hoja (min_samples_leaf)", min_value=1, max_value=20, value=5, help="El n√∫mero m√≠nimo de muestras requeridas para estar en un nodo hoja. Un valor m√°s alto previene el sobreajuste.")
min_samples_split = st.sidebar.slider("M√≠nimo de Muestras para Dividir (min_samples_split)", min_value=2, max_value=40, value=10, help="El n√∫mero m√≠nimo de muestras requeridas para dividir un nodo interno.")

# Par√°metros avanzados
criterion = st.sidebar.selectbox(
    "Criterio de Divisi√≥n (criterion)",
    ("gini", "entropy", "log_loss"),
    index=0, # gini es el predeterminado
    help="La funci√≥n para medir la calidad de una divisi√≥n. 'gini' para impureza Gini, 'entropy' para ganancia de informaci√≥n, 'log_loss' para p√©rdida de logaritmo."
)
splitter = st.sidebar.selectbox(
    "Estrategia de Divisi√≥n (splitter)",
    ("best", "random"),
    index=0, # best es el predeterminado
    help="La estrategia utilizada para elegir la divisi√≥n en cada nodo. 'best' selecciona la mejor divisi√≥n, 'random' selecciona la mejor divisi√≥n aleatoria."
)
# Nota: make_classification genera datos con caracter√≠sticas continuas, por lo que min_impurity_decrease no es directamente aplicable
# y max_features podr√≠a limitar demasiado para un n√∫mero bajo de caracter√≠sticas.
# Estos podr√≠an ser agregados si se desea mayor complejidad.

st.info("Modelo seleccionado: **√Årbol de Decisi√≥n**")

# --- Entrenamiento del Modelo ---
model = DecisionTreeClassifier(
    max_depth=max_depth,
    min_samples_leaf=min_samples_leaf,
    min_samples_split=min_samples_split,
    criterion=criterion,
    splitter=splitter,
    random_state=42 # Para reproducibilidad
)

st.write("Entrenando el √Årbol de Decisi√≥n con los par√°metros seleccionados...")
try:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # --- Resultados del Modelo ---
    st.markdown("---")
    st.subheader("4. Resultados y Desempe√±o del √Årbol de Decisi√≥n ‚úÖ")

    accuracy = accuracy_score(y_test, y_pred)
    st.metric(label="Exactitud (Accuracy) del Modelo", value=f"{accuracy:.4f}")

    st.markdown("#### Reporte de Clasificaci√≥n")
    report = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    st.dataframe(report_df)

    st.markdown("#### Matriz de Confusi√≥n")
    fig_cm, ax_cm = plt.subplots(figsize=(6, 5))
    cm_display = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=plt.cm.Blues, ax=ax_cm)
    st.pyplot(fig_cm)

    # --- Visualizaci√≥n del √Årbol ---
    st.markdown("---")
    st.subheader("5. Visualizaci√≥n del √Årbol de Decisi√≥n Final üå≥")
    st.write("Aqu√≠ puedes ver la estructura del √°rbol de decisi√≥n que fue entrenado con tus datos y par√°metros.")

    # Ajustar tama√±o de la figura para que el √°rbol se vea bien
    fig_tree, ax_tree = plt.subplots(figsize=(25, 15)) # Aumentado el tama√±o
    plot_tree(
        model,
        filled=True,
        feature_names=df.columns[:-1].tolist(),
        class_names=[str(c) for c in sorted(df['Clase'].unique())], # Nombres de clase din√°micos
        ax=ax_tree,
        fontsize=10, # Ajustado el tama√±o de la fuente
        proportion=True, # Muestra la proporci√≥n de muestras en cada nodo
        rounded=True # Bordes redondeados para mejor est√©tica
    )
    plt.title("Estructura del √Årbol de Decisi√≥n", fontsize=16)
    st.pyplot(fig_tree)

except Exception as e:
    st.error(f"¬°Ocurri√≥ un error al entrenar el √Årbol de Decisi√≥n! Por favor, revisa los par√°metros y datos. Error: {e}")

st.markdown("---")
st.markdown("¬°Experimenta con los par√°metros del √°rbol de decisi√≥n en la barra lateral para ver c√≥mo afectan la estructura y el desempe√±o!")

